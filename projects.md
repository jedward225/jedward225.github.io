---
layout: default
title: Projects
permalink: /projects/
---

<div class="page">
  <h1 class="page-title">Projects</h1>
  <div class="project-descriptions">

    <div class="project-description-item">
      <h3>Embodied Reasoner (With OSPP's funding, 150+ Github Stars)</h3>
      <p class="project-role">Main Contributor</p>
      <p>
        Embodied-Reasoner (ER.) is a multimodal model designed for deep reasoning & long-horizon interaction. In OSPP, similar to GSoC, AGIROS Community selected me as the contributor in charge of ER. from all the applicants. I've committed to testing ER. on Alfred and contributed to resolving two key bottlenecks — ambiguity in identical object instances & imprecise targeting of large objects, further improving spatial accuracy and interaction robustness.
      </p>
      <p class="project-links">
        <a href="https://summer-ospp.ac.cn/org/prodetail/251760142?lang=zh&list=pro">Project Page</a> |
        <a href="https://github.com/zwq2018/embodied_reasonere">View on GitHub</a>
      </p>
    </div>
    
    <div class="project-description-item">
      <h3>The Application of Reinforcement Learning for Agents in Automated Bidding Scenarios</h3>
      <p class="project-role">Leader</p>
      <p>
        This project explores strategic bidding in large-scale ad auctions using reinforcement learning. In a simplified simulator, we designed multiple agent types—truthful, conservative, aggressive, and adaptive—under Generalized Second-Price rules with budget and value uncertainties. Our main goal was to train RL-based bidding agents to maximize cumulative profit and ROI in uncertain and competitive environments. The project also integrates advanced reward shaping and lays the foundation for transferring to large-scale real-world auction simulators like the NeurIPS 2024 Auto-Bidding environment. As the team leader, I designed the full simulation framework and led the RL integration, analysis, and visualizations.
      </p>
      <a href="https://github.com/jedward225/rl4agents-in-AutoBidding-Scenarios" class="project-link" target="_blank" rel="noopener noreferrer">View on GitHub</a>
    </div>
    
    <div class="project-description-item">
      <h3>RAGEN & VAGEN: Training Agents by Reinforcing Reasoning (With 2.2k+ Github Stars)</h3>
      <p class="project-role">Contributor</p>
      <p>
        This twin of projects empower agents with RL to operate effectively in interactive and stochastic environments by handling multi-turn interactions and environmental uncertainty. I contributed to developing more environments and mask functions to compute the loss only for the parts generated by the model, which actually made training more stable.
      </p>
      <a href="https://github.com/RAGEN-AI/RAGEN" class="project-link" target="_blank" rel="noopener noreferrer">View on GitHub</a>
    </div>
    
    <div class="project-description-item">
      <h3>WeaveWave: Towards Multimodal Music Generation</h3>
      <p class="project-role">Main Contributor</p>
      <p>
        WeaveWave explores multimodal music generation, aiming to create music from diverse inputs. It bridged existing MLLMs and Text-to-Music systems, proposing end-to-end architectures, and developing a unified generation framework with a custom training pipeline.
      </p>
      <a href="https://github.com/Audiofool934/WeaveWave" class="project-link" target="_blank" rel="noopener noreferrer">View on GitHub</a>
    </div>

  </div>
</div>